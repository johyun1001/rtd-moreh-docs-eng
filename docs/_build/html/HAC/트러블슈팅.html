<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>트러블슈팅 &mdash; Basic Sphinx Example Project  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Basic Sphinx Example Project
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../newfile.html">newfile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../newnewfile.html">newnewfile</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Table of Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../newfile.html">newfile</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Basic Sphinx Example Project</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>트러블슈팅</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/HAC/트러블슈팅.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>트러블슈팅<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h1>
<p><strong>이 문서는 HAC 서비스 사용자를 위해 오류 해결 방안을 제공합니다.</strong>
이 페이지의 해결 가이드대로 진행했음에도 같은 문제가 발생하거나 현재 발생하는 에러코드 및 메시지를 이 페이지에서 찾지 못하실 경우에는 고객지원을 요청해 주시기 바랍니다.</p>
<p>고객지원 요청 시 아래 정보를 포함해주세요.</p>
<ul class="simple">
<li><p>사용하신 SDA Model (moreh-smi 명령어로 확인 가능합니다. 예: 1.5xLarge )</p></li>
<li><p>사용하신 Moreh 솔루션 버전 (moreh-smi로 확인 가능합니다. 예: 22.10.0 )</p></li>
<li><p>사용하신 모델명 또는 계열 (예: ResNet, Transformer 계열 등)</p></li>
<li><p>사용하신 모델 하이퍼 파라미터 (Batch size, Num workers 등)</p></li>
<li><p>어느 시점에서 해당 문제가 발생했는지 (문제 재현 환경에 실행된 명령어 및 소스코드 등)</p></li>
</ul>
<section id="typeerror">
<h2>TypeError<a class="headerlink" href="#typeerror" title="Permalink to this headline"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">TypeError</span></code>는 파이썬 코드에서 가장 흔히 만나게 되는 에러로 데이터 타입과 관련된 에러입니다. 잘못된 데이터의 유형이 연산이나 함수에 적용될 때 발생합니다. <code class="docutils literal notranslate"><span class="pre">TypeError</span></code>에 뒤이어 나오는 내용은 어떤 유형이 불일치하는지에 대한 세부 정보를 제공해줍니다.</p>
<section id="typeerror-add-takes-2-positional-arguments-but-3-were-given">
<h3>TypeError: add_() takes 2 positional arguments but 3 were given<a class="headerlink" href="#typeerror-add-takes-2-positional-arguments-but-3-were-given" title="Permalink to this headline"></a></h3>
<p>위 에러는 크게 아래 3가지 이유로 인해 발생합니다.</p>
<ol class="arabic">
<li><p>Class 메서드에서 self 인수를 지정하지 않아서 발생</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>class Math<span class="o">()</span>:
    <span class="c1"># forgot to specify `self` arg</span>
    def add<span class="o">(</span>a, b<span class="o">)</span>:
        <span class="k">return</span> a + b

<span class="nv">mat</span> <span class="o">=</span> Math<span class="o">()</span>

<span class="c1"># TypeError: Math.add() takes 2 positional arguments but 3 were given</span>
<span class="nv">result</span> <span class="o">=</span> mat.add<span class="o">(</span><span class="m">100</span>, <span class="m">100</span><span class="o">)</span>
</pre></div>
</div>
</li>
<li><p>함수 정의에서 3 번째 인수를 지정하지 않음</p></li>
<li><p>해당 함수는 파라미터를 2개만 받아서 호출되는데 3개의 파라미터가 주어짐</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>

<span class="c1">#TypeError: add() takes 2 positional arguments but 3 were given </span>
<span class="n">add</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="typeerror-invalid-data-type-float">
<h3>TypeError: invalid data type ‘float’<a class="headerlink" href="#typeerror-invalid-data-type-float" title="Permalink to this headline"></a></h3>
<p>위 메시지는 ‘float’ 는 정수로 인식될 수 없다는 의미이며 반드시 정수형을 넘겨줘야되는 파라미터에 실수형을 넘겨주면 발생합니다.</p>
<p>위 에러 메시지가 ‘float’가 아니라 다른 타입일 경우에도 호환되는 데이터타입으로 변경하세요.</p>
</section>
<section id="import-error">
<h3>Import Error<a class="headerlink" href="#import-error" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">ImportError</span></code>는 Import 문에서 모듈을 로드하는 과정에서 문제가 있을 때 발생하는 에러입니다. 주로 파일명이 모듈명과 동일하거나 해당 Python 버전이 정상적으로 설치되지 않아서 발생하는 경우가 많습니다.</p>
</section>
<section id="importerror-home-ubuntu-conda-envs-pytorch2-lib-python3-8">
<h3>ImportError “/home/ubuntu/.conda/envs/pytorch2/lib/python3.8/”<a class="headerlink" href="#importerror-home-ubuntu-conda-envs-pytorch2-lib-python3-8" title="Permalink to this headline"></a></h3>
<p>moreh-smi 명령어를 통해 현재 버전과 pytorch 1.10.0이 정상적으로 설치되었는지 확인 후 0.2.0 버전이라면 아래 명령어로 재설치 하십시오.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>update-moreh --force --target <span class="m">0</span>.2.0 --driver-only
pip install <span class="nv">torch</span><span class="o">==</span><span class="m">1</span>.10.0+cpuonly.moreh0.2.0
</pre></div>
</div>
</section>
<section id="id2">
<h3>학습 속도가 낮아지는 성능 저하 이슈<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<p>Moreh 솔루션의 핵심 기술 중 하나는 GPU에서 연산을 최적화 하는 점입니다. 이때 단점은 처음 CPU 단의 정보들을 GPU 단으로 옮길 때 꽤 많은 처리가 동반됩니다. 대신 GPU에서는 매우 최적화된 연산이라 앞 단의 처리가 좀 느리더라도 이를 상쇄할 수 있을 만큼 빠릅니다.</p>
<p>학습 수행시 데이터 불러오는 작업이 CPU에서 진행된다면 연산하는 과정은 GPU에서 진행됩니다.
연산 과정에서도 사용자 필요에 의해 GPU에서 연산되는 정보를 꺼내올때 <code class="docutils literal notranslate"><span class="pre">.cpu()</span></code>, <code class="docutils literal notranslate"><span class="pre">.item()</span></code> 와 같은 메소드를 사용하게 되는데 이때 pull tensor(GPU단에 있던 tensor 정보를 CPU 단으로 옮기는 과정)가 발생합니다. pull tensor는 GPU단에 있던 정보를 CPU 단으로 옮기는 과정으로 pull tensor가 많아질수록 GPU -&gt; CPU -&gt; GPU -&gt; CPU 로 처리가 반복되어 학습 속도가 낮아지는 원인이 됩니다.
따라서 실행된 코드에<code class="docutils literal notranslate"><span class="pre">.cpu()</span></code>, <code class="docutils literal notranslate"><span class="pre">.item()</span></code> 사용이 많다면 GPU 연산 오프로딩의 결과를 받아오기 위해 다른 연산들의 진행이 중단되기 때문에 GPU를 잘 활용하지 못할 수 있습니다.</p>
<p>학습 처리 속도가 낮거나 학습 진행이 멈추고  <code class="docutils literal notranslate"><span class="pre">Error</span> <span class="pre">message:</span> <span class="pre">Endpoint</span> <span class="pre">timeout</span></code> 에러가 발생하면 <code class="docutils literal notranslate"><span class="pre">moreh-smi</span></code> 커맨드로 확인 시 GPU 사용량이 100%에 가깝다면 batch size 늘려보시기 바랍니다.</p>
</section>
</section>
<section id="id3">
<h2>에러별 해결 가이드<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<p><strong>Table 1.  일반 이슈 (import, 버전, dtype 관련)</strong></p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Error Message</p></th>
<th class="head"><p>Recommended Action</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>TypeError: add_() takes 2 positional arguments but 3 were given</p></td>
<td><p>update-moreh –force –target 22.12.0 후 재시도 또는 코드 수정</p></td>
</tr>
<tr class="row-odd"><td><p>FileNotFoundError: [Errno 2] No such file or directory: ‘/../’</p></td>
<td><p>VM 안에서 환경 변수 설정 및 명령어를 알맞게 입력</p></td>
</tr>
<tr class="row-even"><td><p>AssertionError: train: No labels in “/../“. Can not train without labels.</p></td>
<td><p>해당 모델에 대해 Install script를 최신화 후 기존 모델 및 데이터를 삭제 뒤 재설치</p></td>
</tr>
<tr class="row-odd"><td><p>RuntimeError: Found no NVIDIA driver on your system.</p></td>
<td><p>update-moreh</p></td>
</tr>
<tr class="row-even"><td><p>Pytorch 가상환경 재설치가 진행되지 않음</p></td>
<td><p>새로운 가상환경을 세팅할 경우 pytorch update-moreh 작업이 필요합니다.</p></td>
</tr>
<tr class="row-odd"><td><p>ImportError “/home/ubuntu/.conda/envs/pytorch2/lib/python3.8/”</p></td>
<td><p>moreh-smi 명령어를 통해 현재 버전과 pytorch 1.10.0이 정상적으로 설치되었는지 확인 후 0.2.0 버전이라면 재설치 <code class="docutils literal notranslate"><span class="pre">update-moreh</span> <span class="pre">--force</span> <span class="pre">--target</span> <span class="pre">0.2.0</span> <span class="pre">--driver-only</span></code> <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">torch==1.10.0+cpuonly.moreh0.2.0</span></code></p></td>
</tr>
<tr class="row-even"><td><p>“Too big output tensor”. Terminate runtime context.</p></td>
<td><p>linear layer의 output tensor 사이즈 줄여서 진행</p></td>
</tr>
<tr class="row-odd"><td><p>User defined signal 1:target tensor should have dtype</p></td>
<td><p>dtype 확인 후 고객지원 요청</p></td>
</tr>
</tbody>
</table>
<p><strong>Table 2.  설치 이슈</strong></p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Error Message</p></th>
<th class="head"><p>Recommended Action</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>SystemError: initialization of _internal failed without raising an exception</p></td>
<td><p>cache 초기화 후 재시도 <code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">deactivate</span></code> <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">cache</span> <span class="pre">purge</span></code> <code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">clean</span> <span class="pre">-a</span> <span class="pre">-y</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>AttributeError: module ‘torch.version’ has no attribute ‘moreh’</p></td>
<td><p>기존의 pytorch 가상환경을 삭제하고 MAF 재설치</p></td>
</tr>
</tbody>
</table>
<p><strong>Table 3. 성능 이슈</strong></p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Error Message</p></th>
<th class="head"><p>Recommended Action</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>학습 처리 속도가 낮거나 Error message: Endpoint timeout</p></td>
<td><p>moreh-smi 확인 후 batch size 늘리기</p></td>
</tr>
</tbody>
</table>
<p><strong>Table 4.   메모리 및 가속기 모델 관련</strong></p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Error Message</p></th>
<th class="head"><p>Recommended Action</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Unexpected error: “KT AI Accelerator memory not enough. Try increasing..</p></td>
<td><p>사용중인 SDA Model Memory Size보다 큰 사용량을 보이니 SDA Model을 더 큰 Size로 변경 또는 배치사이즈를 작게 설정</p></td>
</tr>
</tbody>
</table>
</section>
<hr class="docutils" />
<section id="error-faq">
<h2>Error FAQ<a class="headerlink" href="#error-faq" title="Permalink to this headline"></a></h2>
<section id="commands">
<h3>Commands 관련<a class="headerlink" href="#commands" title="Permalink to this headline"></a></h3>
<p><strong>Q. VM에서 lspci 혹은 nvidia-smi를 실행했는데 GPU가 인식이 되지 않습니다.</strong></p>
<p><strong>A.</strong> AI 가속기 정보는 터미널에서 moreh-smi 명령을 실행하여 확인할 수 있습니다. “KT AI Accelerator” 디바이스가 하나 표시되면 정상적으로 AI 가속기가 할당되어 있는 것입니다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>pytorch<span class="o">)</span> ubuntu@vm:~$ moreh-smi
+--------------------------------------------------------------------------------------------------------------+
<span class="p">|</span>  Moreh-SMI <span class="m">0</span>.8.0                                               Client Version: <span class="m">0</span>.8.0  Server Version: <span class="m">0</span>.8.0  <span class="p">|</span>
+--------------------------------------------------------------------------------------------------------------+
<span class="p">|</span>  Device  <span class="p">|</span>        Name         <span class="p">|</span>            Token           <span class="p">|</span>     Model    <span class="p">|</span>  Memory Usage  <span class="p">|</span>  Total Memory  <span class="p">|</span>
+<span class="o">==============================================================================================================</span>+
<span class="p">|</span>       <span class="m">1</span>  <span class="p">|</span>  KT AI Accelerator  <span class="p">|</span>  <span class="nv">ZXhhbXBsZSB0b2tlbiBzdHI</span><span class="o">=</span>  <span class="p">|</span>  small.16gb  <span class="p">|</span>  -             <span class="p">|</span>  -             <span class="p">|</span>
+--------------------------------------------------------------------------------------------------------------+

Processes:
+----------------------------------------------------------+
<span class="p">|</span>  Device  <span class="p">|</span>  Job ID  <span class="p">|</span>  PID  <span class="p">|</span>  Process  <span class="p">|</span>  Memory Usage  <span class="p">|</span>
+<span class="o">==========================================================</span>+
+----------------------------------------------------------+
</pre></div>
</div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>pytorch<span class="o">)</span> ubuntu@vm:~$ moreh-smi
+--------------------------------------------------------------------------------------------------------------+
<span class="p">|</span>  Moreh-SMI <span class="m">0</span>.8.0                                               Client Version: <span class="m">0</span>.8.0  Server Version: <span class="m">0</span>.8.0  <span class="p">|</span>
+--------------------------------------------------------------------------------------------------------------+
<span class="p">|</span>  Device  <span class="p">|</span>        Name         <span class="p">|</span>            Token           <span class="p">|</span>     Model    <span class="p">|</span>  Memory Usage  <span class="p">|</span>  Total Memory  <span class="p">|</span>
+<span class="o">==============================================================================================================</span>+
<span class="p">|</span>       <span class="m">1</span>  <span class="p">|</span>  KT AI Accelerator  <span class="p">|</span>  <span class="nv">ZXhhbXBsZSB0b2tlbiBzdHI</span><span class="o">=</span>  <span class="p">|</span>  small.16gb  <span class="p">|</span>  -             <span class="p">|</span>  -             <span class="p">|</span>
+--------------------------------------------------------------------------------------------------------------+

Processes:
+----------------------------------------------------------+
<span class="p">|</span>  Device  <span class="p">|</span>  Job ID  <span class="p">|</span>  PID  <span class="p">|</span>  Process  <span class="p">|</span>  Memory Usage  <span class="p">|</span>
+<span class="o">==========================================================</span>+
+----------------------------------------------------------+
</pre></div>
</div>
<p>AI 가속기는 PyTorch에서 <code class="docutils literal notranslate"><span class="pre">cuda:0</span></code> 디바이스로 인식되며, 기존 CUDA 디바이스와 호환되는 API를 제공합니다. 따라서 물리적인 GPU가 없더라도 기존에 NVIDIA GPU용으로 작성된 PyTorch 프로그램을 그대로 실행할 수 있습니다.</p>
</section>
<hr class="docutils" />
<section id="ai">
<h3>AI 가속기 관련<a class="headerlink" href="#ai" title="Permalink to this headline"></a></h3>
<p><strong>Q. VM 로그인 시 기본적으로 “pytorch”라는 Anaconda 가상 환경이 활성화됩니다. 다른 가상 환경을 만들 수는 없습니까?</strong></p>
<p>A. “pytorch” 가상 환경에는 이미 Hyperscale AI Computing 서비스를 위한 각종 소프트웨어 설정이 완료되어 있으므로 가급적 해당 환경에서 시스템을 사용해 주시기를 권장 드립니다.</p>
<p>만약 별도의 가상 환경을 생성하기를 희망하실 경우, Python 3.8 버전을 사용하도록 가상 환경을 만들어 주시고 update-moreh –force 명령을 사용하여 해당 가상 환경 내에서 최신 버전의 Hyperscale AI Computing 서비스용 PyTorch를 재설치하시기 바랍니다.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(base) ubuntu@vm:~$ conda create -n your_new_env python=3.8
(base) ubuntu@vm:~$ conda activate your_new_env
(your_new_env) ubuntu@vm:~$ update-moreh --force
</pre></div>
</div>
<p>여러 개의 가상 환경에서 동시에 AI 가속기를 사용하시려는 경우 반드시 모든 가상 환경에서 동일 버전의 PyTorch가 설치되어 있어야 합니다. 각 가상 환경에서 차례로 update-moreh 명령을 실행하여 최신 버전의 소프트웨어를 설치할 수 있습니다.</p>
</section>
<hr class="docutils" />
<section id="id4">
<h3>일반 에러 관련<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<p><strong>Q. PyTorch 프로그램을 실행하였는데 “Two or more processes cannot use KT AI Accelerator at the same time.” 메시지가 출력되고 프로그램이 멈춰 있습니다.</strong></p>
<p><strong>A.</strong> Hyperscale AI Computing 서비스는 하나의 VM에서 AI 가속기를 사용하는 프로그램을 동시에 두 개 이상 실행할 수 없도록 되어 있습니다. 따라서 예를 들어 AI 가속기를 사용하는 train.py 프로그램이 실행 중인 동안 마찬가지로 AI 가속기를 사용하는 inference.py 프로그램을 실행할 경우, 나중에 실행한 프로그램은 메시지를 출력하고 앞에 실행한 프로그램이 끝날 때까지 대기하게 됩니다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>pytorch<span class="o">)</span> ubuntu@vm:~$ python inference.py
...
<span class="o">[</span>info<span class="o">]</span> Requesting resources <span class="k">for</span> KT AI Accelerator from the server...
<span class="o">[</span>warning<span class="o">]</span> KT AI Accelerator is already <span class="k">in</span> use by another process:
<span class="o">[</span>warning<span class="o">]</span>   <span class="o">(</span>pid: <span class="m">10000</span><span class="o">)</span> python train.py
<span class="o">[</span>warning<span class="o">]</span> Two or more processes cannot use KT AI Accelerator at the same time. The program will resume automatically after the process <span class="m">10000</span> terminates...
</pre></div>
</div>
<p>만약 AI 가속기를 사용하는 다른 프로그램이 없는데도 위와 같은 메시지가 표시된다면 다음 질문을 참고하십시오.</p>
<hr class="docutils" />
<p><strong>Q. VM에서 실행 중인 다른 PyTorch 프로그램이 없음에도 불구하고 계속 “Two or more processes cannot use KT AI Accelerator at the same time.” 메시지가 출력됩니다.</strong></p>
<p><strong>A.</strong> 일부 PyTorch 프로그램은 학습/추론 과정에서 데이터를 빠르게 불러 오기 위해 별도의 DataLoader 프로세스를 실행합니다. 이 경우 PyTorch 프로그램이 비정상 종료했을 때(예를 들어 Ctrl+C로 강제 종료했을 때) 주 프로세스는 없어지더라도 DataLoader 프로세스는 없어지지 않고 AI 가속기와 CPU 코어, 메인 메모리를 점유하면서 남아 있는 경우가 있습니다.</p>
<p>현재 VM에 실행 중인 Python 프로세스가 존재하는지 ps aux | grep python 명령으로 확인할 수 있습니다. 또한 실행 중인 모든 Python 프로세스를 pkill python 명령으로 제거할 수 있습니다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>pytorch<span class="o">)</span> ubuntu@vm:~$ ps aux <span class="p">|</span> grep python
root      <span class="m">1700</span>  <span class="m">0</span>.0  <span class="m">0</span>.0 <span class="m">169104</span> <span class="m">17136</span> ?        Ssl  Dec03   <span class="m">0</span>:00 /usr/bin/python3 /usr/bin/networkd-dispatcher --run-startup-triggers
root      <span class="m">1900</span>  <span class="m">0</span>.0  <span class="m">0</span>.0 <span class="m">185956</span> <span class="m">20112</span> ?        Ssl  Dec03   <span class="m">0</span>:00 /usr/bin/python3 /usr/share/unattended-upgrades/unattended-upgrade-shutdown --wait-for-signal
ubuntu    <span class="m">9900</span> <span class="m">84</span>.1  <span class="m">0</span>.1 <span class="m">3688828</span> <span class="m">508348</span> pts/1  Sl   <span class="m">08</span>:50   <span class="m">0</span>:18 python train.py
ubuntu    <span class="m">9901</span> <span class="m">79</span>.5  <span class="m">0</span>.1 <span class="m">3671492</span> <span class="m">491104</span> pts/1  Sl   <span class="m">08</span>:50   <span class="m">0</span>:17 python train.py
ubuntu    <span class="m">9902</span> <span class="m">65</span>.4  <span class="m">0</span>.1 <span class="m">3670744</span> <span class="m">490580</span> pts/1  Sl   <span class="m">08</span>:50   <span class="m">0</span>:14 python train.py
ubuntu    <span class="m">9903</span> <span class="m">67</span>.5  <span class="m">0</span>.1 <span class="m">3671280</span> <span class="m">490440</span> pts/1  Sl   <span class="m">08</span>:50   <span class="m">0</span>:14 python train.py
ubuntu   <span class="m">10000</span>  <span class="m">0</span>.0  <span class="m">0</span>.0  <span class="m">14864</span>  <span class="m">1116</span> pts/2    S+   <span class="m">08</span>:51   <span class="m">0</span>:00 grep --color<span class="o">=</span>auto python
<span class="o">(</span>pytorch<span class="o">)</span> ubuntu@vm:~$ pkill python
<span class="o">(</span>pytorch<span class="o">)</span> ubuntu@vm:~$ ps aux <span class="p">|</span> grep python*
root      <span class="m">1700</span>  <span class="m">0</span>.0  <span class="m">0</span>.0 <span class="m">169104</span> <span class="m">17136</span> ?        Ssl  Dec03   <span class="m">0</span>:00 /usr/bin/python3 /usr/bin/networkd-dispatcher --run-startup-triggers
root      <span class="m">1900</span>  <span class="m">0</span>.0  <span class="m">0</span>.0 <span class="m">185956</span> <span class="m">20112</span> ?        Ssl  Dec03   <span class="m">0</span>:00 /usr/bin/python3 /usr/share/unattended-upgrades/unattended-upgrade-shutdown --wait-for-signal
ubuntu   <span class="m">10001</span>  <span class="m">0</span>.0  <span class="m">0</span>.0  <span class="m">14864</span>  <span class="m">1116</span> pts/2    S+   <span class="m">08</span>:51   <span class="m">0</span>:00 grep --color<span class="o">=</span>auto python
</pre></div>
</div>
<p>만약 실행 중인 Python 프로세스가 전혀 존재하지 않음에도 불구하고 위와 같은 메시지가 표시된다면 moreh-smi –reset 명령으로 GPU 자원을 강제로 할당 해제할 수 있습니다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>pytorch<span class="o">)</span> ubuntu@vm:~$ moreh-smi --reset
Device release success.
</pre></div>
</div>
<p>이 두 가지 방법으로도 문제가 해결되지 않으면 기술 지원을 받으시기 바랍니다.</p>
<hr class="docutils" />
<p><strong>Q. PyTorch 프로그램을 실행하였는데 “Not enough resources are currently available for KT AI Accelerator.” 메시지가 출력되고 프로그램이 멈춰 있습니다.</strong></p>
<p><strong>A.</strong> Hyperscale AI Computing 시스템에 동시에 너무 많은 자원 할당 요청이 들어 올 경우 일시적으로 GPU 자원의 신규 할당이 불가능할 수 있습니다. 이 경우 프로그램이 메시지를 출력하고 GPU 자원이 할당될 때까지 대기할 수 있습니다. 이 경우 가만히 있으면 GPU 자원을 할당 받은 이후 자동으로 실행이 재개됩니다.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>pytorch<span class="o">)</span> ubuntu@vm:~$ python train.py
...
<span class="o">[</span>info<span class="o">]</span> Requesting resources <span class="k">for</span> KT AI Accelerator from the server...
<span class="o">[</span>warning<span class="o">]</span> Not enough resources are currently available <span class="k">for</span> KT AI Accelerator. All resources <span class="k">in</span> the system are being used by other users. The program will resume automatically when resources become available...
</pre></div>
</div>
<hr class="docutils" />
<p><strong>Q. PyTorch 프로그램을 실행하였는데 “The current version of Moreh AI Framework is outdated and no longer supported in the system” 메시지가 출력되고 프로그램이 강제 종료됩니다.</strong></p>
<p><strong>A.</strong> Hyperscale AI Computing 서비스는 지속적으로 소프트웨어 업데이트가 이루어지고 있습니다. 현재 VM에 설치된 소프트웨어가 구 버전인 경우 실제 GPU 쪽 소프트웨어와 호환성이 맞지 않아 프로그램 실행이 불가능할 수 있습니다. 이 경우 터미널에서 update-moreh 명령을 실행하여 소프트웨어를 자동으로 업데이트할 수 있습니다.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(pytorch) ubuntu@vm:~$ update-moreh
Currently installed: 0.8.0
Possible upgrading version: 0.8.1

Do you want to upgrade? (y/n, default:n)
y
...
Finished processing dependencies for moreh-driver==0.8.1

installed : /usr/bin/moreh-smi
installed : /usr/bin/moreh-switch-model
installed : /usr/bin/update-moreh
installed : /usr/lib/libcommunication.so
installed : /usr/lib/libmodnnruntime.so
</pre></div>
</div>
<hr class="docutils" />
<p><strong>Q. PyTorch 프로그램을 실행하였는데 CUDA error가 출력되면서 프로그램이 강제 종료됩니다.</strong></p>
<p><strong>A.</strong> 우선 터미널에서 <code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">list</span> <span class="pre">pytorch</span></code>를 실행하여 PyTorch가 정상 설치되었는지 확인하십시오. PyTorch 버전이 <code class="docutils literal notranslate"><span class="pre">1.7.1+cu110.moreh00.0.0</span></code>와 같은 형식으로 표시되면 정상 설치되어 있는 것입니다.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(pytorch) ubuntu@vm:~$ conda list torch
# packages in environment at /home/ubuntu/.conda/envs/pytorch:
#
# Name                    Version                   Build  Channel
torch                     1.7.1+cu110.moreh22.8.0          pypi_0    pypi
torchaudio                0.7.2                    pypi_0    pypi
torchvision               0.8.2                    pypi_0    pypi
</pre></div>
</div>
<p>그리고 다음과 같이 실행하여 PyTorch 버전 및 Hyperscale AI Computing 플러그인 버전 정보를 확인하십시오. import torch 혹은 torch.version.moreh 결과 에러가 발생하면 PyTorch 혹은 플러그인에 문제가 있는 것입니다.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>pytorch<span class="o">)</span> ubuntu@vm:~$ python
Python <span class="m">3</span>.8.12 <span class="o">(</span>default, Oct <span class="m">12</span> <span class="m">2021</span>, <span class="m">13</span>:49:34<span class="o">)</span>
<span class="o">[</span>GCC <span class="m">7</span>.5.0<span class="o">]</span> :: Anaconda, Inc. on linux
Type <span class="s2">&quot;help&quot;</span>, <span class="s2">&quot;copyright&quot;</span>, <span class="s2">&quot;credits&quot;</span> or <span class="s2">&quot;license&quot;</span> <span class="k">for</span> more information.
&gt;&gt;&gt; import torch
&gt;&gt;&gt; torch.__version__
<span class="s1">&#39;1.7.1&#39;</span>
&gt;&gt;&gt; torch.version.moreh
<span class="s1">&#39;22.8.0&#39;</span>
&gt;&gt;&gt; quit<span class="o">()</span>
<span class="o">(</span>pytorch<span class="o">)</span> ubuntu@vm:~$
</pre></div>
</div>
<p>위 두 단계 중 하나에서 실패한 경우 다음과 같이 실행하여 PyTorch를 재설치해 보십시오.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(pytorch) ubuntu@vm:~$ update-moreh --force
</pre></div>
</div>
<p>애플리케이션에 NVIDIA GPU 의존적인 기능이 포함되어 있는 경우 Hyperscale AI Computing 서비스용 PyTorch가 정상 설치되었더라도 CUDA error가 발생할 수 있습니다. 이 경우 별도로 기술 지원을 받으시기 바랍니다.</p>
<hr class="docutils" />
<p><strong>Q. PyTorch 프로그램을 실행하거나 update-moreh 명령을 실행할 때 “ImportError: numpy.core.multiarray failed to import” 에러가 발생합니다.</strong></p>
<p><strong>A.</strong> 시스템에 너무 낮은 버전(1.16 미만)의 NumPy 라이브러리가 설치되어 문제가 발생할 수 있습니다. 다음과 같이 실행하여 현재 설치된 NumPy 버전을 확인하십시오.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(pytorch) ubuntu@vm:~$ conda list numpy
# packages in environment at /home/ubuntu/.conda/envs/pytorch:
#
# Name                    Version                   Build  Channel
numpy                     1.15.2                   pypi_0    pypi
</pre></div>
</div>
<p>다음과 같이 실행하여 NumPy 버전을 업데이트할 수 있습니다.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(pytorch) ubuntu@vm:~$ conda install numpy -c conda-forge
</pre></div>
</div>
<hr class="docutils" />
<p><strong>Q. PyTorch 프로그램을 실행하거나 moreh-smi 혹은 moreh-switch-model 명령을 실행하였는데 “SDA token is not given.” 에러가 발생합니다.</strong></p>
<p><strong>A.</strong> Hyperscale AI Computing 서비스는 AI 가속기를 식별하기 위해 /etc/moreh/token 파일의 내용을 읽어 옵니다. 다음과 같이 실행하여 해당 파일이 접근 가능한지 확인하십시오.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(pytorch) ubuntu@vm:~$ cat /etc/moreh/token
ZXhhbXBsZSB0b2tlbiBzdHI=
</pre></div>
</div>
<p>만약 위와 같이 실행하였을 때 문제가 발생한다면 기술 지원을 받으시기 바랍니다.</p>
<hr class="docutils" />
<p><strong>Q. moreh-switch-model 명령으로 AI 가속기 모델을 바꾸려고 하니 “The model cannot be switched while the KT AI Accelerator is in use.” 에러가 발생합니다.</strong></p>
<p><strong>A.</strong> AI 가속기에서 프로그램이 실행 중인 동안에는 모델을 바꿀 수 없습니다. 만약 AI 가속기를 사용하는 다른 프로그램이 없는데도 위와 같은 메시지가 표시된다면 다음 질문을 참고하십시오.</p>
<ul class="simple">
<li><p>VM에서 실행 중인 다른 PyTorch 프로그램이 없음에도 불구하고 계속 “Two or more processes cannot use KT AI Accelerator at the same time.” 메시지가 출력됩니다.</p></li>
</ul>
<hr class="docutils" />
<p><strong>Q. PyTorch 프로그램을 실행하였는데 “KT AI Accelerator memory not enough.” 메시지가 출력되고 프로그램이 강제 종료됩니다.</strong></p>
<p><strong>A.</strong> AI 가속기의 메모리 용량이 부족하여 해당 프로그램의 실행이 실패하였음을 의미합니다. 공식 지원 모델을 사용 중인 경우 해당 모델의 매뉴얼에 안내된 권장 batch size를 사용하였는지 확인해 보십시오. 혹은 moreh-switch-model 명령을 사용해 AI 가속기 모델을 더 고사양으로 변경한 다음 프로그램을 실행하여 보십시오.</p>
<hr class="docutils" />
<p><strong>Q. PyTorch 프로그램을 실행하였는데 “Failed to initialize the worker daemon for KT AI Accelerator.” 메시지가 출력되고 프로그램이 강제 종료됩니다.</strong></p>
<p><strong>A.</strong> VM이 할당받은 GPU 자원을 초기화하는 과정에서 문제가 생겼음을 의미합니다. 프로그램을 다시 한 번 실행해 보시고, 같은 증상이 여러 번 반복되면 기술 지원을 받으시기 바랍니다. 기술 지원 시 프로그램을 실행한 시간이 언제인지를 전달해 주시면 더 빨리 도움을 드릴 수 있습니다.</p>
<hr class="docutils" />
<p><strong>Q. PyTorch 프로그램을 실행하였는데 “Connecting to resources on the server” 메시지 직후에 “The connection to the server has been lost.” 메시지가 출력되고 프로그램이 강제 종료됩니다.</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">info</span><span class="p">]</span> <span class="n">Requesting</span> <span class="n">resources</span> <span class="k">for</span> <span class="n">KT</span> <span class="n">AI</span> <span class="n">Accelerator</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">server</span><span class="o">...</span>
<span class="p">[</span><span class="n">info</span><span class="p">]</span> <span class="n">Initializing</span> <span class="n">the</span> <span class="n">worker</span> <span class="n">daemon</span> <span class="k">for</span> <span class="n">KT</span> <span class="n">AI</span> <span class="n">Accelerator</span><span class="o">...</span>
<span class="p">[</span><span class="n">info</span><span class="p">]</span> <span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="mi">1</span><span class="p">]</span> <span class="n">Connecting</span> <span class="n">to</span> <span class="n">resources</span> <span class="n">on</span> <span class="n">the</span> <span class="n">server</span> <span class="p">(</span><span class="mf">192.168.00.00</span><span class="p">:</span><span class="mi">00000</span><span class="p">)</span><span class="o">...</span>
<span class="p">[</span><span class="n">info</span><span class="p">]</span> <span class="n">Establishing</span> <span class="n">links</span> <span class="n">to</span> <span class="n">the</span> <span class="n">resources</span><span class="o">...</span>
<span class="p">[</span><span class="n">error</span><span class="p">]</span> <span class="n">The</span> <span class="n">connection</span> <span class="n">to</span> <span class="n">the</span> <span class="n">server</span> <span class="n">has</span> <span class="n">been</span> <span class="n">lost</span><span class="o">.</span> <span class="n">Please</span> <span class="n">contact</span> <span class="n">technical</span> <span class="n">support</span> <span class="k">if</span> <span class="n">the</span> <span class="n">problem</span> <span class="n">persists</span><span class="o">.</span>
</pre></div>
</div>
<p><strong>A.</strong> VM이 할당받은 GPU 자원에 접속하는 과정에서 문제가 생겼음을 의미합니다. 프로그램을 다시 한 번 실행해 보시고, 같은 증상이 여러 번 반복되면 기술 지원을 받으시기 바랍니다. 기술 지원 시 프로그램을 실행한 시간이 언제인지를 전달해 주시면 더 빨리 도움을 드릴 수 있습니다.</p>
<p>서버 접속 장애로 인해 프로그램이 강제 종료된 경우 해당 실행 건에 대해서는 요금이 부과되지 않습니다.</p>
<hr class="docutils" />
<p><strong>Q. PyTorch 프로그램을 실행하였는데 GPU 연산이 한참 실행되던 중에 갑자기 “The connection to the server has been lost.” 메시지가 출력되고 프로그램이 강제 종료됩니다.</strong></p>
<p><strong>A.</strong> VM이 할당받은 GPU 자원과 통신하는 과정에서 문제가 생겼음을 의미합니다. 프로그램을 다시 한 번 실행해 보시고, 같은 증상이 여러 번 반복되면 기술 지원을 받으시기 바랍니다. 기술 지원 시 프로그램을 실행한 시간이 언제인지를 전달해 주시면 더 빨리 도움을 드릴 수 있습니다.</p>
<p>서버 통신 장애로 인해 프로그램이 강제 종료된 경우 해당 실행 건에 대해서는 요금이 부과되지 않습니다.</p>
<hr class="docutils" />
<p><strong>Q. PyTorch 프로그램을 실행하였는데 “An internal error occurred in the KT AI Accelerator” 메시지가 출력되고 프로그램이 강제 종료됩니다.</strong></p>
<p><strong>A.</strong> GPU 자원 내부에서 연산 에러가 생겼음을 의미합니다. 메시지 아래에 출력되는 “Error message:” 란의 내용을 첨부하여 기술 지원을 받으시기 바랍니다.</p>
<hr class="docutils" />
<p><strong>Q. Conda 가상 환경에서 update-moreh를 통해서 정상적으로 패키지를 설치했지만, Python 패키지들이 정상적으로 동작하지 않습니다.</strong></p>
<p><strong>A.</strong> pip, conda 등을 통해서 Conda 가상환경 내에서 패키지 설치를 시도했지만 원인모를 이유로 Conda 가상 환경 외부인 VM 로컬 환경에 패키지들이 설치되는 경우가 있을 수 있습니다. 이럴 경우에는 정상적으로 모레 솔루션이 동작하지 않을 수 있습니다. 이때에는 아래 디렉토리가 존재한다면 삭제한 후 재시도 바랍니다.</p>
<div class="highlight-jsx notranslate"><div class="highlight"><pre><span></span>rm -rf /home/ubuntu/.local/lib
rm -rf /home/ubuntu/.local/bin 
</pre></div>
</div>
<hr class="docutils" />
<p><strong>Q. VM에 GPT2 RM 설치하다가 “ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: ” 에러가 발생했습니다.</strong></p>
<p><strong>A.</strong> 기존 환경에 설치되어있던 numpy와 충돌이 생기면 가끔 저런 에러가 발생할 수 있습니다. 새로운 환경 만들고 설치합니다. 아래와 같이 실행해보십시오.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install --force-reinstall --no-deps <span class="nv">numpy</span><span class="o">==</span><span class="m">1</span>.23.3
</pre></div>
</div>
<p>위 FAQ에 없는 Moreh 서비스 관련 문의가 생기면 <span class="xref myst">contact&#64;moreh.io</span>로 메일 부탁드립니다.</p>
</section>
</section>
<section id="pytorch-reference">
<h2>Pytorch Reference<a class="headerlink" href="#pytorch-reference" title="Permalink to this headline"></a></h2>
<section id="pytorch-tensor">
<h3>Pytorch Tensor 선언하기<a class="headerlink" href="#pytorch-tensor" title="Permalink to this headline"></a></h3>
<p>Pytorch의 기본 단위는 Tensor이며 딥러닝 학습 시 다루고 있는 행렬 또는 Tensor의 크기를 고려하는 것은 매우 중요합니다.</p>
<p>Tensor의 속성(Attribute)은 크게 형태(shape), 자료형(dtype), 장치(device)로 나눌 수 있습니다.
Tensor 연산 시, 아래 세 가지 속성 중 하나라도 맞지 않는다면 동작하지 않습니다.</p>
<ul class="simple">
<li><p>형태(shape): 텐서의 차원</p></li>
<li><p>자료형(dtype): 텐서의 데이터 구조</p></li>
<li><p>장치(device): 텐서의 GPU 가속 유/무</p></li>
</ul>
<p>위 에러별 해결가이드의 하나의 예시처럼 fully connected layer에서는 큰 Tensor 사이즈를 다루지 못해서 에러가 발생하는 경우가 있기 때문에 아래 레퍼런스(PyTorch에서 Tensor를 구현 방법)을 참고 부탁드립니다.</p>
<p><a class="reference external" href="https://blog.christianperone.com/2018/03/pytorch-internal-architecture-tour/">Pytorch 내부 아키텍처 문서</a>에서 텐서 스토리지와 메인 Tensor의 구성에 관련된 정보를 확인할 수 있습니다.</p>
<p><a class="reference external" href="https://pytorch.org/blog/a-tour-of-pytorch-internals-1/#the-thptensor-type">THP Tensor 유형</a>: Tensor의 대한 이름, 크기, 매핑 방법 등을 정의하는 THPTensor에 관해 소개합니다.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Read the Docs core team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>